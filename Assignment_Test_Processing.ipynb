{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment Test Processing.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPG1NjvXswAs39jx1i6flnF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sehgalsakshi/New-Repository/blob/master/Assignment_Test_Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "252JlZwmP4tT"
      },
      "source": [
        "# Assignment Test Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJ1E_tTiHn5q"
      },
      "source": [
        "**Question 1.** Write a python program to find out the words after '@' from the below sentences with the use of regex.\n",
        "\n",
        "\"xyz@gmail.com\",\n",
        "\"abc@yahoo.com\",\n",
        "\"xyz@hotmail.com\",\n",
        "\"abc@ineuron.ai\",\n",
        "\"xyz@outlook.com\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVuZOEXnIxBr"
      },
      "source": [
        "import re"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7Iu2schDzd_",
        "outputId": "63e31198-9ce1-4d03-d91f-084d3ab1c7cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "email_ids = [\"xyz@gmail.com\",\n",
        "\"abc@yahoo.com\",\n",
        "\"xyz@hotmail.com\",\n",
        "\"abc@ineuron.ai\",\n",
        "\"xyz@outlook.com\"]\n",
        "\n",
        "#find string between @ and end of string\n",
        "regexp = re.compile(\"@(.*)$\") \n",
        "\n",
        "for email in email_ids:\n",
        "  text = regexp.search(email)\n",
        "  if text is not None:\n",
        "    print (text.group(1))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gmail.com\n",
            "yahoo.com\n",
            "hotmail.com\n",
            "ineuron.ai\n",
            "outlook.com\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX_LMMSMJjaw"
      },
      "source": [
        "**Question 2.** Write a python program with the use of regex to take out the word \"New\" from the following sentence.\n",
        "\n",
        "[\"New Delhi is the capital of India\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Nzrpk_GIsyD",
        "outputId": "6e5ca30a-53af-46de-944f-a7079e3e6c91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "regexp = re.compile(r\"\\bnew\\b\", re.I) #with the ignorecase option \n",
        "regexp.findall(\"New Delhi is the capital of India\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['New']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ir3f6F3Jm6z"
      },
      "source": [
        "**Question 3.** Create one python program in which you have to lowercase the sentence first and than delete digits from the following sentence.\n",
        "\n",
        "\"In India, 184 people got affected with Corona virus and 4 are died.\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FsQu_n4JnwH",
        "outputId": "58ef6e3a-0088-40fc-f812-76c6dbdf68ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "s = \"In India, 184 people got affected with Corona virus and 4 are died.\"\n",
        "s = s.lower()\n",
        "s = re.sub(r'[0-9]', '', s)\n",
        "s"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'in india,  people got affected with corona virus and  are died.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOuAK1kkLZYB"
      },
      "source": [
        "**Question 4.** Do stemming, lemmatization and tokenization from the following sentence.\n",
        "\n",
        "\"I hope that, when I have built up my savings, I will be able to travel to Hawai.\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Uvaxp_QLa78"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer, PorterStemmer"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4MTzJtUO2Et",
        "outputId": "a9d11325-77dc-4cb2-f557-e461c6da2a39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmD6wXaMOtMv"
      },
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer()"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lX2FuVw9MPFa"
      },
      "source": [
        "def tokenize(text):\n",
        "  return [word for word in text.split()]\n",
        "  \n",
        "def lemmatize(text):\n",
        "  return ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
        "  \n",
        "def stem(text):\n",
        "  return ' '.join([stemmer.stem(word) for word in text.split()])"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYgSfbaaMgeK",
        "outputId": "e325ca7b-9b60-491b-c385-84fffcd89f45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "s = \"I hope that, when I have built up my savings, I will be able to travel to Hawai.\"\n",
        "'''First lemmatization is done to generate the root form of the inflected words. \n",
        "Then stemming is done to get even shorter words but stem might not be an actual word whereas, lemma is an actual language word'''\n",
        "s = lemmatize(s)\n",
        "s = stem(s)\n",
        "s = tokenize(s)\n",
        "s"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I',\n",
              " 'hope',\n",
              " 'that,',\n",
              " 'when',\n",
              " 'I',\n",
              " 'have',\n",
              " 'built',\n",
              " 'up',\n",
              " 'my',\n",
              " 'savings,',\n",
              " 'I',\n",
              " 'will',\n",
              " 'be',\n",
              " 'abl',\n",
              " 'to',\n",
              " 'travel',\n",
              " 'to',\n",
              " 'hawai.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Seq9vCVCLbat"
      },
      "source": [
        "**Question 5.** Create one python program from the following sentence.\n",
        "\n",
        "\"I love NLP, not you\"\n",
        "\n",
        "output : ['I', 'l', 'N', 'n', 'y']"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Faxu-cv8Lb2V",
        "outputId": "56c58e0a-cf9b-4a64-c4e8-c14efac2093a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "s = \"I love NLP, not you\"\n",
        "s = [word[0] for word in s.split()]  #word[0] will give first character of word\n",
        "s"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I', 'l', 'N', 'n', 'y']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    }
  ]
}